{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 检查GPU\n!nvidia-smi\n","metadata":{"execution":{"iopub.status.busy":"2022-10-15T06:38:55.374174Z","iopub.execute_input":"2022-10-15T06:38:55.374719Z","iopub.status.idle":"2022-10-15T06:38:56.583299Z","shell.execute_reply.started":"2022-10-15T06:38:55.374600Z","shell.execute_reply":"2022-10-15T06:38:56.582061Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Sat Oct 15 06:38:56 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# 克隆Webui\n!git clone https://github.com/Yeleao/SDWeb-Ch /kaggle/working/stable-diffusion-webui","metadata":{"execution":{"iopub.status.busy":"2022-10-15T07:00:16.387341Z","iopub.execute_input":"2022-10-15T07:00:16.387778Z","iopub.status.idle":"2022-10-15T07:00:18.486700Z","shell.execute_reply.started":"2022-10-15T07:00:16.387691Z","shell.execute_reply":"2022-10-15T07:00:18.485502Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/stable-diffusion-webui'...\nremote: Enumerating objects: 290, done.\u001b[K\nremote: Counting objects: 100% (290/290), done.\u001b[K\nremote: Compressing objects: 100% (196/196), done.\u001b[K\nremote: Total 290 (delta 141), reused 240 (delta 91), pack-reused 0\u001b[K\nReceiving objects: 100% (290/290), 1.93 MiB | 5.83 MiB/s, done.\nResolving deltas: 100% (141/141), done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download the model from NovelAILeaks.","metadata":{}},{"cell_type":"code","source":"!mkdir -p /kaggle/working/stable-diffusion-webui/models/Stable-diffusion /kaggle/working/stable-diffusion-webui/models/hypernetworks\n%cd /kaggle/working/stable-diffusion-webui/models/Stable-diffusion\n\n# 模型\n\n# 4G animefull-final-pruned\n!curl -Lo animefull-final-pruned.ckpt https://cloudflare-ipfs.com/ipfs/bafybeicpamreyp2bsocyk3hpxr7ixb2g2rnrequub3j2ahrkdxbvfbvjc4/model.ckpt\n!curl -Lo animefull-final-pruned.yaml https://cloudflare-ipfs.com/ipfs/bafybeiav3j7npiuewbel3mi32l3sidgkw54kuleosbhxmdvddbnvtfi7yu/config.yaml\n\n# 其他\n\n# 安装VAE权重 (可选)\n!curl -Lo animevae.pt https://cloudflare-ipfs.com/ipfs/bafybeiccldswdd3wvg57jhclcq53lvsc6gizasiblwayvhlv6eq4wow7wu/animevae.pt \n\n# 安装超级网络 (可选)\n!curl -L https://cloudflare-ipfs.com/ipfs/bafybeiduanx2b3mcvxlwr66igcwnpfmk3nc3qgxlpwh6oq6m6pxii3f77e/_modules.tar | tar x -C /kaggle/working/stable-diffusion-webui/models/hypernetworks\n\n# 安装自定义的嵌入 (修改,可选)\n#!curl -L https://cloudflare-ipfs.com/ipfs/bafybeie3hdjchxs5tz4n75bos53nhcklslguxchdurc2ynrzcfv2kwyklu/embeddings.tar | tar x -C /content/stable-diffusion-webui/embeddings","metadata":{"execution":{"iopub.status.busy":"2022-10-15T07:01:41.861601Z","iopub.execute_input":"2022-10-15T07:01:41.861995Z","iopub.status.idle":"2022-10-15T07:02:32.632404Z","shell.execute_reply.started":"2022-10-15T07:01:41.861960Z","shell.execute_reply":"2022-10-15T07:02:32.631117Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/stable-diffusion-webui/models/Stable-diffusion\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 4067M  100 4067M    0     0   124M      0  0:00:32  0:00:32 --:--:--  153M\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  1873  100  1873    0     0  15104      0 --:--:-- --:--:-- --:--:-- 15104\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  784M  100  784M    0     0   135M      0  0:00:05  0:00:05 --:--:--  151M\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1004M  100 1004M    0     0   140M      0  0:00:07  0:00:07 --:--:--  155M\n","output_type":"stream"}]},{"cell_type":"markdown","source":"启动WebUi。\n\n命令行参数如下:\n\n--share - 创建一个在线的 gradio.app 链接\n\n--gradio-debug - 打印输出到控制台\n\n--deepdanbooru 启用DeepDanbooru(主要应该是用在训练模型的时候)\n\n--gradio-auth liu:liu123 - 创建用户\n","metadata":{}},{"cell_type":"code","source":"!mkdir /content/stable-diffusion-webui/embeddings","metadata":{"execution":{"iopub.status.busy":"2022-10-15T07:01:24.906587Z","iopub.execute_input":"2022-10-15T07:01:24.906991Z","iopub.status.idle":"2022-10-15T07:01:25.864006Z","shell.execute_reply.started":"2022-10-15T07:01:24.906953Z","shell.execute_reply":"2022-10-15T07:01:25.862699Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/content/stable-diffusion-webui/embeddings’: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/stable-diffusion-webui\n!pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n!COMMANDLINE_ARGS=\"--share --gradio-debug --deepdanbooru --gradio-auth liu:liu123 --vae-path /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animevae.pt\" REQS_FILE=\"requirements.txt\" python launch.py","metadata":{"execution":{"iopub.status.busy":"2022-10-15T06:42:40.513566Z","iopub.execute_input":"2022-10-15T06:42:40.514008Z","iopub.status.idle":"2022-10-15T06:51:16.331242Z","shell.execute_reply.started":"2022-10-15T06:42:40.513945Z","shell.execute_reply":"2022-10-15T06:51:16.329987Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/stable-diffusion-webui\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\nCollecting torch\n  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl (1837.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m667.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.12.0)\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp37-cp37m-linux_x86_64.whl (23.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.11.0)\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp37-cp37m-linux_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.6.15.2)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.3)\nInstalling collected packages: torch, torchvision, torchaudio\n  Attempting uninstall: torch\n    Found existing installation: torch 1.11.0\n    Uninstalling torch-1.11.0:\n      Successfully uninstalled torch-1.11.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.12.0\n    Uninstalling torchvision-0.12.0:\n      Successfully uninstalled torchvision-0.12.0\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 0.11.0\n    Uninstalling torchaudio-0.11.0:\n      Successfully uninstalled torchaudio-0.11.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\nallennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.12.1+cu113 which is incompatible.\nallennlp 2.10.0 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mPython 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]\nCommit hash: b775b3553f5e05a0a924a7b26bfd1f91175fd7f3\nInstalling gfpgan\nInstalling clip\nInstalling deepdanbooru\nCloning Stable Diffusion into repositories/stable-diffusion...\nCloning Taming Transformers into repositories/taming-transformers...\nCloning K-diffusion into repositories/k-diffusion...\nCloning CodeFormer into repositories/CodeFormer...\nCloning BLIP into repositories/BLIP...\nInstalling requirements for CodeFormer\nInstalling requirements for Web UI\nLaunching Web UI with arguments: --share --gradio-debug --deepdanbooru --gradio-auth liu:liu123 --vae-path /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animevae.pt\nError loading script: 文字转蒙版.py\nTraceback (most recent call last):\n  File \"/kaggle/working/stable-diffusion-webui/modules/scripts.py\", line 71, in load_scripts\n    exec(compiled, module.__dict__)\n  File \"/kaggle/working/stable-diffusion-webui/scripts/文字转蒙版.py\", line 16, in <module>\n    from repositories.clipseg.models.clipseg import CLIPDensePredT\nModuleNotFoundError: No module named 'repositories.clipseg'\n\nError loading script: 文转图转图.py\nTraceback (most recent call last):\n  File \"/kaggle/working/stable-diffusion-webui/modules/scripts.py\", line 71, in load_scripts\n    exec(compiled, module.__dict__)\n  File \"/kaggle/working/stable-diffusion-webui/scripts/文转图转图.py\", line 21, in <module>\n    from txt2img2img.dependencies import shortcodes\nModuleNotFoundError: No module named 'txt2img2img'\n\n/kaggle/working/stable-diffusion-webui/scripts/种子过渡.py:81: DeprecationWarning: invalid escape sequence \\(\n  dest_seed = re.sub('\\([^)]*\\)', ',', dest_seed)\nLoading config from: /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animefull-final-pruned.yaml\n/opt/conda/lib/python3.7/site-packages/botocore/httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\nLatentDiffusion: Running in eps-prediction mode\nDiffusionWrapper has 859.52 M params.\nmaking attention of type 'vanilla' with 512 in_channels\nWorking with z of shape (1, 4, 64, 64) = 16384 dimensions.\nmaking attention of type 'vanilla' with 512 in_channels\nDownloading: 100%|███████████████████████████| 939k/939k [00:00<00:00, 2.59MB/s]\nDownloading: 100%|███████████████████████████| 512k/512k [00:00<00:00, 2.10MB/s]\nDownloading: 100%|██████████████████████████████| 389/389 [00:00<00:00, 400kB/s]\nDownloading: 100%|██████████████████████████████| 905/905 [00:00<00:00, 713kB/s]\nDownloading: 100%|█████████████████████████| 4.41k/4.41k [00:00<00:00, 3.98MB/s]\nDownloading: 100%|█████████████████████████| 1.59G/1.59G [01:56<00:00, 14.7MB/s]\nLoading weights [925997e9] from /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animefull-final-pruned.ckpt\nLoading VAE weights from: /kaggle/working/stable-diffusion-webui/models/Stable-diffusion/animevae.pt\nApplying cross attention optimization (Doggettx).\nModel loaded.\nno display name and no $DISPLAY environment variable\nTraceback (most recent call last):\n  File \"launch.py\", line 169, in <module>\n    start_webui()\n  File \"launch.py\", line 164, in start_webui\n    webui.webui()\n  File \"/kaggle/working/stable-diffusion-webui/webui.py\", line 103, in webui\n    demo = modules.ui.create_ui(wrap_gradio_gpu_call=wrap_gradio_gpu_call)\n  File \"/kaggle/working/stable-diffusion-webui/modules/ui.py\", line 1039, in create_ui\n    sd_hijack.model_hijack.embedding_db.load_textual_inversion_embeddings()\n  File \"/kaggle/working/stable-diffusion-webui/modules/textual_inversion/textual_inversion.py\", line 73, in load_textual_inversion_embeddings\n    mt = os.path.getmtime(self.embeddings_dir)\n  File \"/opt/conda/lib/python3.7/genericpath.py\", line 55, in getmtime\n    return os.stat(filename).st_mtime\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/stable-diffusion-webui/embeddings'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"在网站使用结束，上面的命令行结束后启用，将生成的图片全部打包生成一个文件夹，以提供下载","metadata":{}},{"cell_type":"code","source":"!zip -r /kaggle/working/outputs /kaggle/working/stable-diffusion-webui/outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}